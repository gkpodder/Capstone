\documentclass{article}

\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{hyperref}

\hypersetup{
    colorlinks=true,       % false: boxed links; true: colored links
    linkcolor=red,          % color of internal links (change box color with linkbordercolor)
    citecolor=green,        % color of links to bibliography
    filecolor=magenta,      % color of file links
    urlcolor=cyan           % color of external links
}

\title{Hazard Analysis\\\progname}

\author{\authname}

\date{}

\input{../Comments}
\input{../Common}

\begin{document}

\maketitle
\thispagestyle{empty}

~\newpage

\pagenumbering{roman}

\begin{table}[hp]
\caption{Revision History} \label{TblRevisionHistory}
\begin{tabularx}{\textwidth}{llX}
\toprule
\textbf{Date} & \textbf{Developer(s)} & \textbf{Change}\\
\midrule
Date1 & Name(s) & Description of changes\\
Date2 & Name(s) & Description of changes\\
... & ... & ...\\
\bottomrule
\end{tabularx}
\end{table}

~\newpage

\tableofcontents

~\newpage

\pagenumbering{arabic}

\wss{You are free to modify this template.}

\section{Introduction}

In the context of this project, a hazard is defined as any potential source of 
harm or adverse effect that could result from the use, misuse, or failure of the 
AI-powered assistive technology platform. 
Hazards may arise from interactions between the system and the user, the system 
and the computing environment, or from internal system errors. 
They can manifest as physical, cognitive, or informational risks, and may affect 
user safety, privacy, accessibility, or the integrity of computer operations.

By documenting hazards in a structured and traceable manner, the development team 
can make informed design and operational decisions, while also providing guidance 
for future maintenance, updates, and testing of the system.

\section{Scope and Purpose of Hazard Analysis}
The purpose of this hazard analysis is to identify and evaluate possible
hazards linked to the Proxi system, a voice and text driven assistant
designed to improve accessibility and productivity for all users.
The scope of this analysis includes the software components of Proxi such
as the voice and text input handling, MCP integration, system automation
features, and interaction with the desktop operating system. It also
covers potential issues related to data handling, user commands, and
accessibility features. Hardware failures, external network infrastructure,
and third-party service outages are outside the scope of this analysis.
The main losses that could occur due to these hazards include accidental
file deletion or modification, loss or exposure of user data, compromised
accessibility for people with disabilities, and reduced user trust caused
by incorrect or misleading actions. These issues could also lead to major
productivity loss if important commands fail, run incorrectly, or if key
accessibility features stop working as expected. Even though Proxi does
not control hardware or other safety-critical devices, failures in the
software could still cause real harm through data loss, security breaches,
inefficiency, or user frustration.
The goal of this hazard analysis is to find and understand these risks
early in the project so that effective prevention and mitigation
strategies can be planned and built into the design.


\section{System Boundaries and Components}

\subsection{System Boundaries}

The boundaries of the system are defined by its scope of control and interaction:
\begin{itemize}
    \item The system accepts user input through \textbf{speech} or \textbf{text} 
    interfaces.
    \item It processes these inputs internally using natural language understanding 
    and task planning components.
    \item It interacts with external computer applications and operating system tools
     to perform user-requested actions (e.g., sending emails, opening documents, managing files).
    \item It outputs responses or task results back to the user through \textbf{text} 
    or \textbf{speech synthesis}.
\end{itemize}

Elements outside the system boundary include:
\begin{itemize}
    \item The underlying \textbf{operating system} and \textbf{hardware} on which 
    the platform runs.
    \item Third-party applications or APIs that the platform may invoke.
    \item The user’s physical hardware devices such as microphones, speakers, or 
    assistive peripherals.
    \item Network infrastructure and external AI services (if used for speech 
    recognition or task execution).
\end{itemize}

\subsection{Major System Components}

The system can be conceptually divided into the following major components:

\begin{enumerate}
    \item \textbf{User Interface Module (UI):}
    Handles all communication with the user, including speech-to-text (STT) input, text input, and text-to-speech (TTS) or visual feedback output.

    \item \textbf{Natural Language Understanding (NLU) Engine:}
    Interprets user intent from raw speech or text input and converts it into structured commands for the planning module.

    \item \textbf{Task Planning and Agent Manager:}
    Responsible for decomposing user intent into executable subtasks, invoking specialized software agents, and monitoring task progress.

    \item \textbf{Tool and System Integration Layer:}
    Provides controlled access to the computer’s applications and resources (e.g., file manager, web browser, email client) through APIs or system commands.

    \item \textbf{Knowledge Base and Context Manager:}
    Maintains context about the user’s current session, preferences, and system state to support coherent interactions and task continuity.

    \item \textbf{Data Storage and Logging Component:}
    Stores session logs, error reports, and user preferences while ensuring compliance with privacy and data protection requirements.

    \item \textbf{Security and Permissions Module:}
    Manages access control, ensures safe execution of actions on behalf of the user, and prevents unauthorized or unsafe operations.
\end{enumerate}

These components collectively form the system boundary for hazard analysis. Hazards may arise from failures, misuse, or unexpected interactions among these components or between the system and its external environment.

\section{Critical Assumptions}
The hazard analysis is based on a few key assumptions about how Proxi will
be used and the environment it will run in:
\begin{enumerate}
\item The system will run on supported desktop operating systems like
Windows, macOS, or Linux with the needed permissions already set.
\item Users will give clear and intentional commands. Some commands may be
misunderstood, but we do not assume the system will be used in a harmful way.
\item The MCP integration layer, system APIs, and other tools Proxi works
with are expected to behave as described, even though failures are still
possible.
\item Network issues may slow down some features, but basic local actions
and automation will still work without an internet connection.
\item A working microphone or similar input device is expected to be
available and set up correctly for voice input on the user's device.
\end{enumerate}
These assumptions help us focus on realistic hazards and plan how to handle
them. They guide the analysis and reflect how Proxi is expected to work in
everyday use.



\section{Failure Mode and Effect Analysis}

\wss{Include your FMEA table here. This is the most important part of this document.}
\wss{The safety requirements in the table do not have to have the prefix SR.
The most important thing is to show traceability to your SRS. You might trace to
requirements you have already written, or you might need to add new
requirements.}
\wss{If no safety requirement can be devised, other mitigation strategies can be
entered in the table, including strategies involving providing additional
documentation, and/or test cases.}

\section{Safety and Security Requirements}

\wss{Newly discovered requirements.  These should also be added to the SRS.  (A
rationale design process how and why to fake it.)}

\section{Roadmap}

\wss{Which safety requirements will be implemented as part of the capstone timeline?
Which requirements will be implemented in the future?}

\newpage{}

\section*{Appendix --- Reflection}

\wss{Not required for CAS 741}

\input{../Reflection.tex}

\begin{enumerate}
    \item What went well while writing this deliverable? 
    \item What pain points did you experience during this deliverable, and how
    did you resolve them?
    \item Which of your listed risks had your team thought of before this
    deliverable, and which did you think of while doing this deliverable? For
    the latter ones (ones you thought of while doing the Hazard Analysis), how
    did they come about?
    \item Other than the risk of physical harm (some projects may not have any
    appreciable risks of this form), list at least 2 other types of risk in
    software products. Why are they important to consider?
\end{enumerate}

\section*{Reflection – Amanbeer Minhas}

\begin{enumerate}
\item What went well while writing this deliverable?\\
Writing this deliverable went well because we already had a clear idea of
our system from the SRS and FMEA work. Breaking the project into components
helped me think about hazards more systematically and kept the analysis
organized. I also felt more confident in identifying potential risks and
writing about them in a structured way.

\item What pain points did you experience during this deliverable, and how
did you resolve them?\\
One challenge was figuring out how detailed to make each section without
overcomplicating the document. I also found it tricky to write about hazards
without repeating the same points as the SRS. I resolved this by focusing on
specific examples from our project, like MCP integration and OS automation,
and connecting them directly to potential risks.

\item Which of your listed risks had your team thought of before this
deliverable, and which did you think of while doing this deliverable? For
the latter ones (ones you thought of while doing the Hazard Analysis), how
did they come about?\\
We had already thought about risks like incorrect command execution and
permission issues earlier in the project. However, risks such as operating
system compatibility problems and deployment-related failures came up while
writing this hazard analysis. They became more obvious once we broke the
system into components and looked deeper into how each part could fail.

\item Other than the risk of physical harm (some projects may not have any
appreciable risks of this form), list at least 2 other types of risk in
software products. Why are they important to consider?\\
One major risk is data loss or corruption, which can harm user trust and
make the system unreliable. Another risk is accessibility failure, where
users with limitations might not be able to use the software as intended.
Both are important to consider because they affect user confidence,
usability, and the overall success of the product.
\end{enumerate}

\section*{Reflection – Gourob Podder}

\begin{enumerate}
    \item \textbf{What went well while writing this deliverable:}  
    The process of identifying system boundaries and major components went 
    smoothly because the project architecture was already conceptually clear from 
    prior SRS work. Clearly defining modules such as the User Interface, Natural 
    Language Understanding, and Agent Manager helped us organize potential hazards 
    systematically. Collaboration among team members also allowed us to quickly 
    align on how risks might manifest in both software and user interactions.

    \item \textbf{Pain points and resolutions:}  
    One major challenge was determining the level of detail appropriate for a hazard 
    analysis without drifting into system design. It was sometimes difficult to 
    distinguish between a “hazard” and a general usability concern. We resolved 
    this by referring to established safety engineering definitions and by 
    focusing on identifying sources of harm or adverse outcomes rather than 
    design flaws. Another difficulty was quantifying abstract risks such as privacy 
    or misinterpretation of user intent, which we addressed through scenario-based 
    brainstorming.

    \item \textbf{Previously known and newly discovered risks:}  
    Before this deliverable, we had already recognized usability and privacy risks, 
    such as the potential for misinterpreted commands or unauthorized data access. 
    During the hazard analysis, new risks emerged — particularly concerning the 
    interaction between components, like potential failures in the Task Planning 
    module leading to unintended system actions, or risks of dependency on unreliable 
    external APIs. These were identified as we systematically examined each subsystem 
    and its interface boundaries, revealing points of failure that were not apparent 
    at a higher level.

    \item \textbf{Other types of risks in software products:}  
    Beyond physical harm, two important categories of risk are:  
    \begin{itemize}
        \item \textbf{Privacy and Data Security Risks:} Improper handling of user
         data, especially for users relying on speech interfaces, can lead to 
         breaches of sensitive personal information. Considering this is essential 
         for maintaining user trust and legal compliance.  
        \item \textbf{Reliability and Availability Risks:} System downtime or 
        malfunction could prevent users from completing essential tasks, which 
        is especially critical for those depending on assistive technologies. 
        Evaluating and mitigating such risks ensures consistent accessibility and 
        improves user confidence.
    \end{itemize}
\end{enumerate}


\end{document}